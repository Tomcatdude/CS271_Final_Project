{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Naive Bayes Models To Predict Sleep Patterns Based On Average Daily Action Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authored by Tom Odem on 19 November 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
    "from sklearn.model_selection import train_test_split,KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no user_tags: 501\n",
      "no user_tags: 503\n",
      "no user_tags: 507\n",
      "no user_tags: 520\n",
      "no user_tags: 523\n",
      "no user_tags: 529\n",
      "no user_tags: 532\n",
      "no user_tags: 544\n",
      "no user_tags: 547\n",
      "no user_tags: 634\n",
      "no user_tags: 658\n",
      "no user_tags: 661\n",
      "no user_tags: 662\n",
      "no user_tags: 664\n",
      "no user_tags: 668\n"
     ]
    }
   ],
   "source": [
    "X = modules.get_and_avg_data() #get data averaged over 7 day increments\n",
    "Y = X['avg_sleep'].copy() #extract labels from set\n",
    "X = X.drop(labels=['depression_class','avg_sleep'], axis = 1) #drop the depression class because we will be using the depression scores instead and drop avg_sleep because those are our labels\n",
    "X = X.apply(modules.categorize_column, axis=0) #categorize the columns into 3 categories 0 = less than average, 1 = average, 3 = more than average\n",
    "Y = modules.categorize_column(Y) #categorize labels in the same way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For averaged user data, our data is obtained via three different file models: user_information.csv, which lists every user who participated in the study, user_tag files, which are individual files for each user that documents every action that was recorded throughout the study, and user_data files, which documents exact times that activity tags are triggered and also records the user's step amount at each tag trigger. The function get_and_avg_data() first opens the user_data file and user_tag data file for a user and computes the amount they slept, number of times they ate, number of times they drank, number of times they completed a self care act, and the amount of steps they took for everyday the user had data recorded. After getting the daily counts, the function computes averages over avg_of_n_days days, which is a user defined function parameter. This is done by selecting the first avg_of_n_days day from the daily data and computing the average of every feature. These averages, along with the user's depression information, is then appended as an individual new user to an averages dataframe. We then select the next avg_of_n_days days and compute averages , then the next, and so on until we reach the end of the recorded days. This is done for each user in which we have files for, to get a final number of 37-users-with-files * (number-of-days-recorded-for-user / avg_of_n_days) data points to train and classify with.\n",
    "One might think, \"why not average over all days for each user?\" While that would be optimal, we only have 37 users who actually had retrievable data, and trying to train these big fancy models with only 37 data points would not be very productive. So, we split the data up into countless new users based on average over days. In essence, all of the new \"pseudo-users\" created from a single user are treated as individual users who just happen to have the same depression information. Since we are trying to find patterns in depression based on daily activity within a population, we can assume that this small population can also represent a wider range of population, which is simulated via these averages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to predict sleep, so our labels will be average daily sleep amount, while our data points will consist of the remaining 5 features: steps, amount of eating, amount of drinking, amount of self care, and depression score. These numerical values, both labels and features, are all continuous, which is not good for a Naive Bayes model. To remedy this, we run each feature through a function that categorizes this continuous data into three categories. The function first takes the mean and standard deviation of the feature, then categorizes the data based on it's distance from one standard deviation from the mean. If a value is less than one standard deviation from the mean, it is labeled as less than average(0). If a value is greater than one standard deviation from the mean, it is labeled as greater than average(2). If a value falls within one standard deviation of the mean, then it is labeled as average(1). This categorization is done for both the labels and all data point features. So, we are now predicting \"less than average\", \"more than average\", or \"average\" amount of sleep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 10-fold cross validation to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy given by 10-fold cross validation Naive Bayes with alpha of 1: 0.7148572884811417\n",
      "average accuracy given by 10-fold cross validation Naive Bayes with alpha of 2: 0.7148572884811417\n"
     ]
    }
   ],
   "source": [
    "#evaluate categorical naive bayes\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=57) #define how many k-folds we want, shuffle the data when choosing\n",
    "clf = CategoricalNB(alpha=1) #we are testing categorical naive bayes with an alpha of 1\n",
    "accuracy_scores = cross_val_score(clf, X, Y, cv=k_fold, n_jobs=1) #evaluate the above defined model using 10-fold cross validation\n",
    "print(f'average accuracy given by 10-fold cross validation Naive Bayes with alpha of 1: {np.mean(accuracy_scores)}')\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=57) #define how many k-folds we want, shuffle the data when choosing\n",
    "clf = CategoricalNB(alpha=2) #we are testing categorical naive bayes with an alpha of 2\n",
    "accuracy_scores = cross_val_score(clf, X, Y, cv=k_fold, n_jobs=1) #evaluate the above defined model using 10-fold cross validation\n",
    "print(f'average accuracy given by 10-fold cross validation Naive Bayes with alpha of 2: {np.mean(accuracy_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy given by 10-fold cross validation Naive Bayes with alpha of 1: 0.6934760448521916\n",
      "average accuracy given by 10-fold cross validation Naive Bayes with alpha of 2: 0.6934760448521916\n"
     ]
    }
   ],
   "source": [
    "#evaluate multinomial naive bayes\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=57) #define how many k-folds we want, shuffle the data when choosing\n",
    "clf = MultinomialNB(alpha=1) #we are testing multinomial naive bayes with an alpha of 1\n",
    "accuracy_scores = cross_val_score(clf, X, Y, cv=k_fold, n_jobs=1) #evaluate the above defined model using 10-fold cross validation\n",
    "print(f'average accuracy given by 10-fold cross validation Naive Bayes with alpha of 1: {np.mean(accuracy_scores)}')\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=57) #define how many k-folds we want, shuffle the data when choosing\n",
    "clf = MultinomialNB(alpha=2)#we are testing multinomial naive bayes with an alpha of 2\n",
    "accuracy_scores = cross_val_score(clf, X, Y, cv=k_fold, n_jobs=1) #evaluate the above defined model using 10-fold cross validation\n",
    "print(f'average accuracy given by 10-fold cross validation Naive Bayes with alpha of 2: {np.mean(accuracy_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested both a categorical Naive Bayes and a multinomial Naive Bayes based approach to train on and classify our data. We chose to only use these two due to a couple of reasons. First, our data is just not suited for some other types of Naive Bayes implementations because of various reasons including our data not being binary valued categories, not being too unbalanced, among others. Secondly, these models intuitively fit the data more. Looking at the categorical approach, our data was transformed into categories to change them to discrete values, which seems perfect for a model named \"categorical Naive Bayes\". For the multinomial approach, we read a research paper about spam filtering that had a section that described different versions of Naive Bayes, and we selected the model that fit our data the most (Metsis). Since our data is basically just averages of counts, it may prove to be multinomial like. \n",
    "\n",
    "We tested both models using 10-fold cross validation on the entire dataset to find which model performs best. We also tested each model with the most common Laplacian smoothing alpha values of 1 and 2. After running all four models, we found that the categorical approach was the more accurate model with an accuracy of 71.49%, while the multinomial approach achieved a 69.35% accuracy. The values of the alpha parameter did not change the accuracy between tests for either of the approaches. Because of this, we chose to use an alpha value of 1 for our trained model.\n",
    "\n",
    "Metsis, Vangelis & Androutsopoulos, Ion & Paliouras, Georgios. (2006). Spam Filtering with Naive Bayes - Which Naive Bayes?. In CEAS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating a model based on the best found model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up our data into trains and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes model: 0.6972477064220184\n"
     ]
    }
   ],
   "source": [
    "#train and evaluate the categorical naive bayes\n",
    "\n",
    "clf = CategoricalNB(alpha=1) #define the model\n",
    "clf.fit(X_train, Y_train) #fit the model\n",
    "Y_pred = clf.predict(X_test) #predict the labels of test set\n",
    "accuracy = accuracy_score(Y_pred, Y_test) #compute the accuracy\n",
    "print(f'Accuracy of Naive Bayes model: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes model: 0.6146788990825688\n"
     ]
    }
   ],
   "source": [
    "#train and evaluate the multinomial naive bayes\n",
    "\n",
    "clf = MultinomialNB(alpha=1) #define the model\n",
    "clf.fit(X_train, Y_train) #fit the model\n",
    "Y_pred = clf.predict(X_test) #predict the labels of test set\n",
    "accuracy = accuracy_score(Y_pred, Y_test) #compute the accuracy\n",
    "print(f'Accuracy of Naive Bayes model: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ['Multinomial', 'Categorical']\n",
    "accuracies = [61.5, 69.72]\n",
    "plt.title('Accuracy Of Both Naive Bayes Models Tested')\n",
    "plt.bar(models,accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a categorical Naive Bayes, we trained on a training set and evaluated on a test set, using a 90-10 split. The model used an alpha value of 1 for Laplacian smoothing. This model gave us an accuracy of 69.72%. What this means in terms of the data is that if we are given a user's average daily habits, we can predict if they get more than average, less than average, or an average amount of sleep with 69.72% accuracy. This is much better than if we had used the multinomial Naive Bayes, which gave an accuracy of 61.47% using the same parameters and training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
