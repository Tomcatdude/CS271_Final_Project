{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data and turn it into data usable by LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no user_tags: 520\n",
      "no user_tags: 532\n",
      "no user_tags: 503\n",
      "no user_tags: 503\n",
      "no user_tags: 523\n",
      "no user_tags: 544\n",
      "no user_tags: 529\n",
      "no user_tags: 661\n",
      "no user_tags: 658\n",
      "no user_tags: 664\n",
      "no user_tags: 634\n",
      "no user_tags: 507\n",
      "no user_tags: 547\n",
      "no user_tags: 501\n",
      "no user_tags: 668\n",
      "no user_tags: 662\n"
     ]
    }
   ],
   "source": [
    "#Get data and then split it into sequences (X) and class (Y)\n",
    "X = modules.get_and_dayitise_data()#read in data from csv and turn into day by day sequences\n",
    "Y = np.array([x[0] for x in X])\n",
    "X = np.array([x[1:] for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only the activity sequences that have more than some number of activities per day\n",
    "lowest_num_activities = 3\n",
    "Y = np.array([Y[i] for i in range(len(Y)) if len(X[i])>lowest_num_activities])\n",
    "X = [x for x in X if len(x)>lowest_num_activities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sleep = np.median(Y)\n",
    "Y[Y < average_sleep] = 0 #not a lot of sleep\n",
    "Y[Y >= average_sleep] = 1 #lots of sleep\n",
    "\n",
    "onehot_encoder = OneHotEncoder(categories='auto')\n",
    "Y = onehot_encoder.fit_transform(Y.reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.772058823529413"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the labels into numeric values (each row is not the same length)\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(np.hstack(X)) #flatten X so we can fit the encoder to all possible values in each row\n",
    "X = np.array([le.transform(x)+1 for x in X]) #now transform each row into corresponding encoding using the fitted encoder, add 1 so that we don't have any zeroes because 0 is for padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize the arrays to be of size average length\n",
    "average_length = int(np.median([len(x) for x in X])) #get the average length\n",
    "#if the length is less than the average, pad it with zeroes. if the length is over, resize it\n",
    "X = np.array([np.resize(np.pad(x,(0,average_length-len(x))), average_length) if len(x) < average_length else np.resize(x,average_length) for x in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 68)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 10, 100)           1200      \n",
      "                                                                 \n",
      " spatial_dropout1d_6 (Spatia  (None, 10, 100)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,802\n",
      "Trainable params: 81,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding = 100\n",
    "num_unique_labels = len(le.classes_)+1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_unique_labels, embedding, input_length=average_length))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339, 10)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19/19 [==============================] - 3s 28ms/step - loss: 0.6241 - accuracy: 0.7344 - val_loss: 0.4960 - val_accuracy: 0.7985\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4429 - accuracy: 0.8025 - val_loss: 0.4492 - val_accuracy: 0.7910\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4165 - accuracy: 0.8149 - val_loss: 0.4358 - val_accuracy: 0.8060\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3974 - accuracy: 0.8290 - val_loss: 0.4239 - val_accuracy: 0.8134\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3890 - accuracy: 0.8290 - val_loss: 0.4255 - val_accuracy: 0.8209\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8389\n",
      "Test set\n",
      "  Loss: 0.382\n",
      "  Accuracy: 0.839\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
