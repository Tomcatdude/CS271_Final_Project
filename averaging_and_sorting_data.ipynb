{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging And Sorting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding The Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")#there are some warnings that show up from pandas that don't effect us, so we just mute them\n",
    "\n",
    "#authored by Tom Odem on 12 November 2023\n",
    "#computes the averages of data over a set increments of time for users, then merges averages with respective depression measurements\n",
    "def get_and_avg_data(avg_over_n_days = 7):\n",
    "#avg_over_n_days: integer value of the amount of days to compute averages over. defaults to 7, which computes weekly averages\n",
    "    \n",
    "    users_df = pd.read_csv('user_information.csv') #read the user_information.csv file to get user ids, depression scores, etc\n",
    "    n_days_df = pd.DataFrame(columns=['user_id','avg_step','avg_sleep','avg_drink', 'avg_eat','avg_care']) #initialize the dataframe that will hold averages over n days\n",
    "\n",
    "    #go through all users in user_information.csv\n",
    "    for user in users_df['user_id']:\n",
    "        if(exists('user_data/data_'+str(user)+'.csv')): #if the user's data csv exists then open it and continue\n",
    "            user_df = pd.read_csv('user_data/data_'+str(user)+'.csv')\n",
    "            \n",
    "            #find daily step count\n",
    "            user_df['client_time']= [pd.to_datetime(i).date() for i in user_df['client_time']]#turn the datetime entries into just dates\n",
    "            steps= user_df.groupby(['client_time'])['step'].max().reset_index().rename(columns={'client_time':'date'}).astype({'date':object})#compute the daily step count by just taking the maximum step count everyday, rename client_time to date so we can merge with others, force date to be object for merging\n",
    "            \n",
    "            if(exists('user_tags/'+str(user)+'.csv')): #if the user's tags csv exists then open it and continue\n",
    "                u = pd.read_csv('user_tags/'+str(user)+'.csv')\n",
    "                u = u.drop(columns=['end'])\n",
    "\n",
    "\n",
    "                #find daily sleep time\n",
    "                #finds the time the user wakes up everyday\n",
    "                wakeup_time = u.loc[(u['labelName'] == 'Wake up')]\n",
    "                wakeup_time['start'] = [pd.to_datetime(t)  for t in wakeup_time['start']]\n",
    "                wakeup_time['date']= [pd.to_datetime(t).date() for t in wakeup_time['start']]\n",
    "                wakeup_time['hour']= [pd.to_datetime(t).time() for t in wakeup_time['start']]\n",
    "\n",
    "                #finds the time the user went to sleep everyday\n",
    "                sleep_time = u.loc[(u['labelName'] == 'Sleep')]\n",
    "                sleep_time['start'] = [pd.to_datetime(t) for t in sleep_time['start']]\n",
    "                sleep_time['date']= [(pd.to_datetime(t)+ pd.Timedelta(days=1)).date() for t in sleep_time['start']]\n",
    "                sleep_time['hour']= [pd.to_datetime(t).time() for t in sleep_time['start']]\n",
    "                \n",
    "                #computes the amount of time the user slept daily\n",
    "                r = pd.merge(wakeup_time, sleep_time, on ='date')\n",
    "                r['start_y'] = pd.to_datetime(r['start_y'])\n",
    "                r['start_x'] = pd.to_datetime(r['start_x'])\n",
    "                r['sleeptime'] = (-1*(r['start_y'] - r['start_x']).astype('timedelta64[m]'))/60 #find the difference between when they woke up from when they went to sleep in hours\n",
    "                r = r[['sleeptime','date']].groupby('date').mean().reset_index().astype({'date':object})#we only need the date and the sleeptime, we rest the index to change it back \n",
    "                                                                                                        #to a dataframe, and we want to force teh date to be of type object so that we can always merge even if there are no entries\n",
    "                \n",
    "                #find daily number of times the user drank\n",
    "                drinktime = u.loc[(u['labelName'] == 'Drink')] #we only want the entries that correlate to drinking\n",
    "                drinktime['date'] = [pd.to_datetime(t).date() for t in drinktime['start']] #gives us the date that the drink happened, since we do not need to know the exact time\n",
    "                drinktime = drinktime.rename(columns={'labelName':'drinktime'}).groupby('date').count().drop(['start'], axis = 1).reset_index().astype({'date':object}) #finds the number of times the user drank a day by grouping by the date, we drop start becase\n",
    "                                                                                                                                                                        #we only need to know the date, we reset the index to turn it back into a dataframe, and we force date to be object for merging\n",
    "                \n",
    "                #find daily number of times the user ate\n",
    "                eattime = u.loc[(u['labelName'] == 'Eat')] #we only want the entries that correlate to eating\n",
    "                eattime['date'] = [pd.to_datetime(t).date() for t in eattime['start']] #gives us the date that the eat happened, since we do not need to know the exact time\n",
    "                eattime = eattime.rename(columns={'labelName':'eattime'}).groupby('date').count().drop(['start'], axis = 1).reset_index().astype({'date':object}) #finds the number of times the user ate a day by grouping by the date, we drop start becase\n",
    "                                                                                                                                                                #we only need to know the date, we reset the index to turn it back into a dataframe, and we force date to be object for merging\n",
    "                \n",
    "                #find daily number of times the user performed and act of self care\n",
    "                self_care = u.loc[(u['labelName'] == 'Take shower') | (u['labelName'] == 'Go to bathroom')] #we only want the entries that correlate to self care\n",
    "                self_care['date'] = [pd.to_datetime(t).date() for t in self_care['start']] #gives us the date that the self care happened, since we do not need to know the exact time\n",
    "                self_care = self_care.rename(columns={'labelName':'selfcare'}).groupby('date').count().drop(['start'], axis = 1).reset_index().astype({'date':object}) #finds the number of times the user self cared a day by grouping by the date, we drop start becase\n",
    "                                                                                                                                                                        #we only need to know the date, we reset the index to turn it back into a dataframe, and we force date to be object for merging\n",
    "\n",
    "                #merge all of the daily counts on time\n",
    "                data_frames = [r,drinktime,eattime,self_care,steps] #the dataframes to be merged\n",
    "                data_by_day_df = reduce(lambda  left,right: pd.merge(left,right,on=['date'],how='outer'), data_frames) #pd.merge can only merge two at a time, so we have to run merge over all of the dataframes\n",
    "\n",
    "                max_date = data_by_day_df['date'].max() #find the latest date in the dataframe\n",
    "\n",
    "                current_date = data_by_day_df['date'].min() #we start at the earliest date in the dataframe\n",
    "\n",
    "                \n",
    "                #take averages over avg_over_n_days incriments from the first day to the last day\n",
    "                while current_date < max_date: #while we haven't reached the last day\n",
    "                    n_days_from_current_date = current_date+datetime.timedelta(days=avg_over_n_days) #find the day that is avg_over_n_days away from the current date\n",
    "\n",
    "                    range = (data_by_day_df['date'] >= current_date) & (data_by_day_df['date'] < n_days_from_current_date) #define the range of dates we select from data_by_day_df \n",
    "\n",
    "                    #compute the averages of each activity within the given range\n",
    "                    avg_sleep = np.mean(data_by_day_df.loc[range]['sleeptime'])\n",
    "                    avg_drink = np.mean(data_by_day_df.loc[range]['drinktime'])\n",
    "                    avg_eat = np.mean(data_by_day_df.loc[range]['eattime'])\n",
    "                    avg_care = np.mean(data_by_day_df.loc[range]['selfcare'])\n",
    "                    avg_step = np.mean(data_by_day_df.loc[range]['step'])\n",
    "\n",
    "                    #add the averages to predic_df\n",
    "                    temp = pd.DataFrame([[user,avg_step, avg_sleep, avg_drink, avg_eat, avg_care]], columns=['user_id','avg_step','avg_sleep','avg_drink', 'avg_eat', 'avg_care'])\n",
    "                    n_days_df = pd.concat([n_days_df, temp])\n",
    "\n",
    "\n",
    "                    current_date = n_days_from_current_date #our range did not include the day avg_over_n_days away, so that day is now our current day to start from\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "        \n",
    "            else:\n",
    "                print(f'no user_tags: {user}') #the tags csv was missing for this user\n",
    "        else:\n",
    "            print(f'no user_data: {user}') #the data csv was missing for this user\n",
    "\n",
    "\n",
    "    averages_df = pd.merge(n_days_df, users_df[['user_id','depression_class', 'depression_score']], on='user_id').set_index('user_id') #merge the averages with their respective depression class and deppression score\n",
    "    return averages_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no user_tags: 520\n",
      "no user_tags: 532\n",
      "no user_tags: 503\n",
      "no user_tags: 503\n",
      "no user_tags: 523\n",
      "no user_tags: 544\n",
      "no user_tags: 529\n",
      "no user_tags: 661\n",
      "no user_tags: 658\n",
      "no user_tags: 664\n",
      "no user_tags: 634\n",
      "no user_tags: 507\n",
      "no user_tags: 547\n",
      "no user_tags: 501\n",
      "no user_tags: 668\n",
      "no user_tags: 662\n"
     ]
    }
   ],
   "source": [
    "#example, getting averages over an increment of 5 days\n",
    "averages_df = get_and_avg_data(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_step</th>\n",
       "      <th>avg_sleep</th>\n",
       "      <th>avg_drink</th>\n",
       "      <th>avg_eat</th>\n",
       "      <th>avg_care</th>\n",
       "      <th>depression_class</th>\n",
       "      <th>depression_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>104.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2575.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>3919.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>3993.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2041.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>6734.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>6615.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>4678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>5550.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1510 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_step  avg_sleep  avg_drink  avg_eat  avg_care depression_class  \\\n",
       "user_id                                                                       \n",
       "519         104.5        NaN        NaN      NaN       NaN         Moderate   \n",
       "519        2575.0        NaN        NaN      NaN       NaN         Moderate   \n",
       "519        3919.0        NaN        NaN      3.0       NaN         Moderate   \n",
       "519        3993.0        NaN        NaN      3.0       NaN         Moderate   \n",
       "519        2041.0        NaN        NaN      2.0       NaN         Moderate   \n",
       "...           ...        ...        ...      ...       ...              ...   \n",
       "655        6734.0        NaN        NaN      2.0       1.0           Normal   \n",
       "655           NaN        NaN        NaN      NaN       NaN           Normal   \n",
       "655        6615.0        NaN        NaN      NaN       NaN           Normal   \n",
       "655        4678.0        NaN        NaN      2.0       NaN           Normal   \n",
       "655        5550.5        NaN        NaN      2.5       1.0           Normal   \n",
       "\n",
       "         depression_score  \n",
       "user_id                    \n",
       "519                   0.5  \n",
       "519                   0.5  \n",
       "519                   0.5  \n",
       "519                   0.5  \n",
       "519                   0.5  \n",
       "...                   ...  \n",
       "655                   0.0  \n",
       "655                   0.0  \n",
       "655                   0.0  \n",
       "655                   0.0  \n",
       "655                   0.0  \n",
       "\n",
       "[1510 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the dataframe\n",
    "averages_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3373f5e4286784464e69fd09210bfe4c348f89b58f1edca7f7cdbc29737fecd0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
