{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging And Sorting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding The Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")#there are some warnings that show up from pandas that don't effect us, so we just mute them\n",
    "\n",
    "#authored by Tom Odem on 12 November 2023\n",
    "#computes the averages of data over a set increments of time for users, then merges averages with respective depression measurements\n",
    "def get_and_avg_data(avg_over_n_days = 7):\n",
    "#avg_over_n_days: integer value of the amount of days to compute averages over. defaults to 7, which computes weekly averages\n",
    "    \n",
    "    users_df = pd.read_csv('user_information.csv') #read the user_information.csv file to get user ids, depression scores, etc\n",
    "    n_days_df = pd.DataFrame(columns=['user_id','avg_step','avg_sleep','avg_drink', 'avg_eat','avg_care']) #initialize the dataframe that will hold averages over n days\n",
    "\n",
    "    #go through all users in user_information.csv\n",
    "    for user in users_df['user_id']:\n",
    "        if(exists('user_data/data_'+str(user)+'.csv')): #if the user's data csv exists then open it and continue\n",
    "            user_df = pd.read_csv('user_data/data_'+str(user)+'.csv')\n",
    "            \n",
    "            #find daily step count\n",
    "            user_df['client_time']= [pd.to_datetime(i).date() for i in user_df['client_time']]#turn the datetime entries into just dates\n",
    "            steps= user_df.groupby(['client_time'])['step'].max().reset_index().rename(columns={'client_time':'date'}).astype({'date':object})#compute the daily step count by just taking the maximum step count everyday, rename client_time to date so we can merge with others, force date to be object for merging\n",
    "            \n",
    "            if(exists('user_tags/'+str(user)+'.csv')): #if the user's tags csv exists then open it and continue\n",
    "                u = pd.read_csv('user_tags/'+str(user)+'.csv')\n",
    "                u = u.drop(columns=['end'])\n",
    "\n",
    "\n",
    "                #find daily sleep time\n",
    "                #finds the time the user wakes up everyday\n",
    "                wakeup_time = u.loc[(u['labelName'] == 'Wake up')]\n",
    "                wakeup_time['start'] = [pd.to_datetime(t)  for t in wakeup_time['start']]\n",
    "                wakeup_time['date']= [pd.to_datetime(t).date() for t in wakeup_time['start']]\n",
    "                wakeup_time['hour']= [pd.to_datetime(t).time() for t in wakeup_time['start']]\n",
    "\n",
    "                #finds the time the user went to sleep everyday\n",
    "                sleep_time = u.loc[(u['labelName'] == 'Sleep')]\n",
    "                sleep_time['start'] = [pd.to_datetime(t) for t in sleep_time['start']]\n",
    "                sleep_time['date']= [(pd.to_datetime(t)+ pd.Timedelta(days=1)).date() for t in sleep_time['start']]\n",
    "                sleep_time['hour']= [pd.to_datetime(t).time() for t in sleep_time['start']]\n",
    "                \n",
    "                #computes the amount of time the user slept daily\n",
    "                r = pd.merge(wakeup_time, sleep_time, on ='date')\n",
    "                r['start_y'] = pd.to_datetime(r['start_y'])\n",
    "                r['start_x'] = pd.to_datetime(r['start_x'])\n",
    "                r['sleeptime'] = (-1*(r['start_y'] - r['start_x']).astype('timedelta64[m]'))/60 #find the difference between when they woke up from when they went to sleep in hours\n",
    "                r = r[['sleeptime','date']].groupby('date').mean().reset_index().astype({'date':object})#we only need the date and the sleeptime, we rest the index to change it back \n",
    "                                                                                                        #to a dataframe, and we want to force teh date to be of type object so that we can always merge even if there are no entries\n",
    "                \n",
    "                #find daily number of times the user drank\n",
    "                drinktime = u.loc[(u['labelName'] == 'Drink')] #we only want the entries that correlate to drinking\n",
    "                drinktime['date'] = [pd.to_datetime(t).date() for t in drinktime['start']] #gives us the date that the drink happened, since we do not need to know the exact time\n",
    "                drinktime = drinktime.rename(columns={'labelName':'drinktime'}).groupby('date').count().drop(['start'], axis = 1).reset_index().astype({'date':object}) #finds the number of times the user drank a day by grouping by the date, we drop start becase\n",
    "                                                                                                                                                                        #we only need to know the date, we reset the index to turn it back into a dataframe, and we force date to be object for merging\n",
    "                \n",
    "                #find daily number of times the user ate\n",
    "                eattime = u.loc[(u['labelName'] == 'Eat')] #we only want the entries that correlate to eating\n",
    "                eattime['date'] = [pd.to_datetime(t).date() for t in eattime['start']] #gives us the date that the eat happened, since we do not need to know the exact time\n",
    "                eattime = eattime.rename(columns={'labelName':'eattime'}).groupby('date').count().drop(['start'], axis = 1).reset_index().astype({'date':object}) #finds the number of times the user ate a day by grouping by the date, we drop start becase\n",
    "                                                                                                                                                                #we only need to know the date, we reset the index to turn it back into a dataframe, and we force date to be object for merging\n",
    "                \n",
    "                #find daily number of times the user performed and act of self care\n",
    "                self_care = u.loc[(u['labelName'] == 'Take shower') | (u['labelName'] == 'Go to bathroom')] #we only want the entries that correlate to self care\n",
    "                self_care['date'] = [pd.to_datetime(t).date() for t in self_care['start']] #gives us the date that the self care happened, since we do not need to know the exact time\n",
    "                self_care = self_care.rename(columns={'labelName':'selfcare'}).groupby('date').count().drop(['start'], axis = 1).reset_index().astype({'date':object}) #finds the number of times the user self cared a day by grouping by the date, we drop start becase\n",
    "                                                                                                                                                                        #we only need to know the date, we reset the index to turn it back into a dataframe, and we force date to be object for merging\n",
    "\n",
    "                #merge all of the daily counts on time\n",
    "                data_frames = [r,drinktime,eattime,self_care,steps] #the dataframes to be merged\n",
    "                data_by_day_df = reduce(lambda  left,right: pd.merge(left,right,on=['date'],how='outer'), data_frames) #pd.merge can only merge two at a time, so we have to run merge over all of the dataframes\n",
    "\n",
    "                max_date = data_by_day_df['date'].max() #find the latest date in the dataframe\n",
    "\n",
    "                current_date = data_by_day_df['date'].min() #we start at the earliest date in the dataframe\n",
    "\n",
    "                \n",
    "                #take averages over avg_over_n_days incriments from the first day to the last day\n",
    "                while current_date < max_date: #while we haven't reached the last day\n",
    "                    n_days_from_current_date = current_date+datetime.timedelta(days=avg_over_n_days) #find the day that is avg_over_n_days away from the current date\n",
    "\n",
    "                    range = (data_by_day_df['date'] >= current_date) & (data_by_day_df['date'] < n_days_from_current_date) #define the range of dates we select from data_by_day_df \n",
    "\n",
    "                    #compute the averages of each activity within the given range\n",
    "                    avg_sleep = np.mean(data_by_day_df.loc[range]['sleeptime'])\n",
    "                    avg_drink = np.mean(data_by_day_df.loc[range]['drinktime'])\n",
    "                    avg_eat = np.mean(data_by_day_df.loc[range]['eattime'])\n",
    "                    avg_care = np.mean(data_by_day_df.loc[range]['selfcare'])\n",
    "                    avg_step = np.mean(data_by_day_df.loc[range]['step'])\n",
    "\n",
    "                    #add the averages to predic_df\n",
    "                    temp = pd.DataFrame([[user,avg_step, avg_sleep, avg_drink, avg_eat, avg_care]], columns=['user_id','avg_step','avg_sleep','avg_drink', 'avg_eat', 'avg_care'])\n",
    "                    n_days_df = pd.concat([n_days_df, temp])\n",
    "\n",
    "\n",
    "                    current_date = n_days_from_current_date #our range did not include the day avg_over_n_days away, so that day is now our current day to start from\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "        \n",
    "            else:\n",
    "                print(f'no user_tags: {user}') #the tags csv was missing for this user\n",
    "        else:\n",
    "            print(f'no user_data: {user}') #the data csv was missing for this user\n",
    "\n",
    "\n",
    "    averages_df = pd.merge(n_days_df, users_df[['user_id','depression_class', 'depression_score']], on='user_id').set_index('user_id') #merge the averages with their respective depression class and deppression score\n",
    "    return averages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no user_tags: 520\n",
      "no user_tags: 532\n",
      "no user_tags: 503\n",
      "no user_tags: 503\n",
      "no user_tags: 523\n",
      "no user_tags: 544\n",
      "no user_tags: 529\n",
      "no user_tags: 661\n",
      "no user_tags: 658\n",
      "no user_tags: 664\n",
      "no user_tags: 634\n",
      "no user_tags: 507\n",
      "no user_tags: 547\n",
      "no user_tags: 501\n",
      "no user_tags: 668\n",
      "no user_tags: 662\n",
      "1510\n"
     ]
    }
   ],
   "source": [
    "# example, getting averages over an increment of 5 days\n",
    "averages_df = get_and_avg_data(5)\n",
    "print(len(averages_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
