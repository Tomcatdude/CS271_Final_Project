{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Random Forest Models To Predict Sleep Patterns Based On Average Daily Action Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split,KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving and categorizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no user_tags: 520\n",
      "no user_tags: 532\n",
      "no user_tags: 503\n",
      "no user_tags: 503\n",
      "no user_tags: 523\n",
      "no user_tags: 544\n",
      "no user_tags: 529\n",
      "no user_tags: 661\n",
      "no user_tags: 658\n",
      "no user_tags: 664\n",
      "no user_tags: 634\n",
      "no user_tags: 507\n",
      "no user_tags: 547\n",
      "no user_tags: 501\n",
      "no user_tags: 668\n",
      "no user_tags: 662\n"
     ]
    }
   ],
   "source": [
    "X = modules.get_and_avg_data() #get data averaged over 7 day increments\n",
    "Y = X['avg_sleep'].copy() #extract labels from set\n",
    "X = X.drop(labels=['depression_class','avg_sleep'], axis = 1) #drop the depression class because we will be using the depression scores instead and drop avg_sleep because those are our labels\n",
    "X = X.apply(modules.categorize_column, axis=0) #categorize the columns into 3 categories 0 = less than average, 1 = average, 3 = more than average\n",
    "Y = modules.categorize_column(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best parameters for our random forest using 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters we will be testing in cross validation\n",
    "num_trees = [5,10,20,30,40,50,60,70,80,90,100]\n",
    "criterions = ['gini', 'entropy', 'log_loss']\n",
    "min_samples_splits = [2,4,8,16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only \"overbearing\" individual tree parameter we test is min_samples_split, which controls the least amount of samples we need to split the tree. This is because min_samples_split affects all other parameters in the created decision trees and could possibly lead to overfitting if left too low. Additionally, all other \"overbearing\" parameters can limit expansion of a tree where the expansion would most likely be useful. Max depth, for example, would halt any more splits from happening, even when the splits would help us discriminate between samples more accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the best parameters\n",
    "               #num_tree, criterion, min_sample_split, accuracy\n",
    "best_results = [0,        None,      0,                0.0]\n",
    "for num_tree in num_trees:\n",
    "    for criterion in criterions:\n",
    "        for min_sample_split in min_samples_splits:\n",
    "            k_fold = KFold(n_splits=10, shuffle=True, random_state=57)\n",
    "            clf = RandomForestClassifier(n_estimators=num_tree, criterion=criterion,min_samples_split=min_sample_split, random_state=56)\n",
    "            accuracy_scores = cross_val_score(clf, X, Y, cv=k_fold, n_jobs=1)\n",
    "            avg_accuracy = np.mean(accuracy_scores)\n",
    "            if(avg_accuracy > best_results[3]):\n",
    "                best_results = [num_tree, criterion, min_sample_split, avg_accuracy]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters found via 10-fold cross validation: \n",
      "num_tree-70 \n",
      "criterion-entropy \n",
      "min_sample_split-16\n"
     ]
    }
   ],
   "source": [
    "#get the best parameters\n",
    "num_tree = best_results[0]\n",
    "criterion = best_results[1]\n",
    "min_sample_split = best_results[2]\n",
    "print(f'The best parameters found via 10-fold cross validation: \\nnum_tree-{num_tree} \\ncriterion-{criterion} \\nmin_sample_split-{min_sample_split}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate our best found model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up our data into trains and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest model with best found parameters: 0.7706422018348624\n",
      "Accuracy of Random Forest model with default parameters: 0.7522935779816514\n"
     ]
    }
   ],
   "source": [
    "#evaluate our model using the best found parameters\n",
    "clf = RandomForestClassifier(n_estimators=num_tree, criterion=criterion,min_samples_split=min_sample_split, random_state=56)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "best_accuracy = accuracy_score(Y_pred, Y_test)\n",
    "\n",
    "#now evaluate a model where all parameters were default\n",
    "clf = RandomForestClassifier(random_state=56)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "null_accuracy = accuracy_score(Y_pred, Y_test)\n",
    "\n",
    "#print the accuracies for comparision\n",
    "print(f'Accuracy of Random Forest model with best found parameters: {best_accuracy}\\nAccuracy of Random Forest model with default parameters: {null_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
